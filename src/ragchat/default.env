# Default configuration for RAGChat
# These settings will be used unless overridden by user-specific .env files
# or command line arguments

# Model settings
RAGCHAT_MODEL=llama3.3
RAGCHAT_EMBED_MODEL=nomic-embed-text
RAGCHAT_TEMPERATURE=0.7
# RAGCHAT_MAX_TOKENS=1024  # Uncomment to set max tokens

# Provider settings
RAGCHAT_PROVIDER=ollama  # Options: ollama, openai, anthropic, google
# RAGCHAT_API_KEY=         # Your API key (if not using provider-specific env vars)
# RAGCHAT_API_BASE=        # Custom API base URL (if needed)

# Provider-specific API keys (can be set instead of RAGCHAT_API_KEY)
# OPENAI_API_KEY=          # For OpenAI models
# ANTHROPIC_API_KEY=       # For Anthropic Claude models
# GOOGLE_API_KEY=          # For Google Gemini models

# Vector store settings
# RAGCHAT_PERSIST_DIR is not set here as it defaults to ~/.ragchat/chroma_db or $RAGCHAT_HOME/chroma_db

# Behavior settings
RAGCHAT_NOFALLBACK=false
RAGCHAT_DEBUG=false
RAGCHAT_SHOW_THOUGHTS=false

# Additional LLM options can be set with RAGCHAT_LLM_* prefix
# Examples:
# RAGCHAT_LLM_STREAMING=true
# RAGCHAT_LLM_TOP_P=0.9
